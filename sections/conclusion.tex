\chapter{Conclusion}\label{chapter:conclusion}
As distributed and parallel computing applications are becoming increasingly compute-intensive and data-driven, \gls{io} performance demands are ever growing.
%
Computing accelerators (such as \glspl{fpga} and \glspl{gpu}), high-throughput \glspl{nic}, and fast storage devices like \glspl{nvme}, are now commonplace in most modern computer systems.
%
Nevertheless, distributing such \gls{io} resources in a way that maximizes both performance and resource utilization is a challenge for heterogeneous computing clusters. 
%
To avoid that individual machines becoming performance bottlenecks, resources must be shared efficiently between machines in the cluster.



In this dissertation, we have addressed this challenge and presented our SmartIO framework for sharing \gls{io} resources between machines connected over \gls{pcie}.
%
SmartIO makes it possible to scale out and use more hardware resources than there are available in a single machine, as machines can dynamically share their internal devices and memory resources with other machines in a \gls{pcie} network. 
%
Using SmartIO, remote resources can be used as if they were installed in the local machine, without any performance degradation compared to local access and without requiring adaptions to device drivers or application software.




\section{Summary}\label{sec:summary}
% - What was the target problem?
Connecting two or more computer systems over \gls{pcie} is possible by using \glspl{pcientb}.
%
\Glspl{ntb} have memory address translation capabilities that makes it possible for a machine to map \glspl{segment} of remote memory directly into local address space.
%
However, leveraging \glspl{ntb} to share the internal devices and memory of a machine with other, remote machines is a challenge, as the use of a remote resource requires software to be aware of the fact that the resource is on the other side of an \gls{ntb}.
%
For example, a device driver operating a remote device must use addresses that correspond to the remote device's address space when initiating \gls{dma} transfers or configuring interrupts.
%
This additional complexity makes it infeasible to rely on \glspl{ntb} alone to implement a resource sharing solution, as it would require extensive modifications to existing software.



% - What did you develop?
To solve this, we have developed our SmartIO framework for sharing devices and memory resources between machines connected with \glspl{ntb}.
%
Our solution consists of ``\glspl{lender}'', machines lending out one or more of its internal devices, and ``\glspl{borrower}'', machines using such a device.
%
Machines can act as \gls{lender} and \gls{borrower} at the same time, making SmartIO fully distributed.
%
Any type of \gls{pcie} device may be shared, as SmartIO is built on standard \gls{pcie}.
%
SmartIO keeps track of which machines devices and \glspl{memorysegment} reside in, and is able to map resources on behalf of devices and resolve memory addresses as they are seen by devices.
%
As such, SmartIO provides a logical decoupling of devices and which \glspl{lendermachine} they are installed in, solving the challenge of managing multiple address spaces and making remote resources appear and behave as if they are local.




SmartIO supports three different methods of device sharing:
%
\begin{itemize}
    \item Our \textbf{\gls{dl}} sharing method makes it possible to dynamically assign a \gls{pcie} device to a remote \gls{borrowermachine}.
        %
        By using a \gls{shadowdev}, the device appears \gls{hotadded} to the local device tree on the \gls{borrower}.
        %
        The fact that the device is remote is made transparent to the system, allowing the device to be used by native device drivers and application software as if it was locally installed.


    \item Our \textbf{\gls{mdev}} extension to the \gls{kvm} makes it possible to distribute devices to \glspl{vm} running on remote machines, by facilitating \emph{\gls{passthrough}} of a device to the \gls{vmguest}.
        %
        Application software and device drivers running inside the \gls{vmguest} can directly interact the physical device, without compromising the isolation of the virtualized environment.


    \item Our \textbf{\gls{sisciapiext}} makes it possible to \gls{disaggregate} devices and memory resources in software.
        %
        We have extended the \gls{sisciapi} with device-oriented programming semantics and device driver support functionality, making core SmartIO capabilities available through the same shared-memory \gls{api} used to write cluster applications.
        %
        Using this \gls{apiext}, we have also implemented a \textbf{proof-of-concept \gls{nvme} driver} that demonstrates how devices can be \gls{disaggregated} and shared with multiple machines at the same time.
        
\end{itemize}



% - What were the results?
We have performed an extensive performance evaluation, consisting of a comprehensive collection of synthetic performance benchmarking and realistic workloads.
%
We have made a point out of using standard benchmarking software and device drivers, as well as a wide variety of \gls{pcie} devices, in order to demonstrate the completeness of our SmartIO framework.
%
Particularly, we have performed comparison tests where we compare the performance of a workload using remote resources to the same workload running only on a local system.
%
The results prove that, when conditions are similar, the SmartIO sharing methods \textbf{do not add \emph{any} performance overhead} compared to using local resources.
%
Furthermore, we have also explored how different network topologies affect the performance, and have identified situations where the \gls{iommu} can become a potential performance bottleneck.
%
Finally, our exhaustive performance test suite also includes tests using our proof-of-concept \gls{nvme} driver that highlights possibilities that are enabled by our shared-memory approach to device sharing.






\section{Revisiting the problem statement}\label{sec:discussion}
Although many \gls{disaggregation} solutions for sharing resources over a network already exist, these solutions are often inadequate as discussed in \cref{sec:rw}. 
%%
For instance, \gls{disaggregation} solutions based on \gls{rdma} introduce additional software complexity and indirections that leads to a disparity in performance, compared to a local machine using local resources. 
%%
\Gls{pcie}-based \gls{disaggregation} solutions do not have such performance issues, since they facilitate the use of resources using native \gls{pcie}.
%%
However, \gls{pcie}-based \gls{disaggregation} solutions are limited to sharing devices installed in dedicated servers, as they lack the shared-memory capabilities necessary for sharing the \emph{inner} resources of individual machines. 



Thus, the main goal of this dissertation was not simply to implement yet another \gls{disaggregation} solution, but developing a new, more flexible solution with zero overhead by using a novel approach:
%
unifying traditional device \gls{io} with distributed, shared-memory computing by leveraging the memory mapping capabilities of \glspl{ntb}.
%
Such a solution should allow the inner devices and memory of machines to be shared with, and used by, remote machines in a cluster, as if these resources were local to the remote machines using them.
%
In \cref{sec:problem}, we broke down the challenges of this goal into \crefrange{obj:distributed}{obj:experiments}:



% How did we answer objectives 1-6? 
% For each objective, state clearly how it was solved and the contribution of it (refer back to contributions in 1.5)
% Also make it clear how the contribution helps solve the overall research question as well.



\objdistributed*%
%
Using SmartIO, machines act as ``\glspl{lender}'' and ``\glspl{borrower}''. 
%
\Gls{lender} registers one or more of its devices with SmartIO, allowing these devices to be used by remote machines.
%
A \gls{borrower} is a system that is currently using such a device.
%
Any \gls{pcie} device may be registered with SmartIO and shared, as demonstrated particularly by our extensive performance evaluation in \paperref{tocs:eval}.
%
We implemented three different sharing methods for our solution, namely \gls{dl}, \gls{mdev}, and the \gls{exttosisciapi}.
%
These sharing methods are detailed in \cref{nossdav,srmpds,cc,tocs}.
%
SmartIO is fully distributed, allowing any machine to act as \gls{lender} or \gls{borrower}, or even acting as both at the same time.



\objtransparent*%
%


% fully distrubted, act as lender and


% Refer back to the main research question
%However, there are some caveats performance considerations regarding \gls{pcie} paths and \glspl{iommu}.

% How does this move the world forward?




%%% contrast the below to smartio
%%%% something state of the art?
%%%% novelty of our approach

%our solution combines traditional device \gls{io} with shared-memory capabilities


\section{Future work}\label{sec:fw}

mention new NVMe kernel space driver here

security / safety

disaggregated memory - new interconnects

iommu in tree structures is a challenge - ats? other solutions?


scaling

%Our system effectively makes all
%hosts, including their internal resources (both devices and memory), part of a common PCIe domain.


%With SmartIO, the hard separation between local and remote is blurred, as remote resources can be used as if they were locally installed and with native PCIe performance.


%Using the \gls{sisciapi}, application memory can be exported as \glspl{sharedsegment}, and \glspl{segment} in remote machines can be mapped into a local application process' virtual address space.
%By building on these concepts, our \lgls{apiext}{extension} makes it possible for a device driver implementation to use all the memory \gls{disaggregation} capabilities of \gls{sisci}, while also providing functionality for abstracting away the location of memory resources and resolving addresses between different address spaces.
%
%A device driver implemented using our \gls{apiext} can be agnostic about the underlying \gls{pcie} network topology, as devices may \gls{dma} directly to \glspl{sharedsegment}, regardless of whether they are local or remote.
%
%It is even possible to map device memory of other devices registered with SmartIO, for example devices borrowed using \gls{dl}.
